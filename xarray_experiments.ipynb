{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `xarray` experiments in stats module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "from arviz import ess, psislw\n",
    "import numpy as np\n",
    "from collections.abc import Sequence\n",
    "from xarray import apply_ufunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to be ufunc compatible\n",
    "def psislw_1D(log_weights, cutoff_ind, cutoffmin, k_min, reff=1.0):\n",
    "    \"\"\"\n",
    "    Pareto smoothed importance sampling (PSIS).\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_weights : array\n",
    "        Array of length n_observations\n",
    "    reff : float\n",
    "        relative MCMC efficiency, `ess / n`\n",
    "    Returns\n",
    "    -------\n",
    "    lw_out : array\n",
    "        Smoothed log weights\n",
    "    kss : array\n",
    "        Pareto tail indices\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.copy(log_weights)\n",
    "\n",
    "    # improve numerical accuracy\n",
    "    x -= np.max(x)\n",
    "    # sort the array\n",
    "    x_sort_ind = np.argsort(x)\n",
    "    # divide log weights into body and right tail\n",
    "    xcutoff = max(x[x_sort_ind[cutoff_ind]], cutoffmin)\n",
    "\n",
    "    expxcutoff = np.exp(xcutoff)\n",
    "    tailinds, = np.where(x > xcutoff)  # pylint: disable=unbalanced-tuple-unpacking\n",
    "    x_tail = x[tailinds]\n",
    "    tail_len = len(x_tail)\n",
    "    if tail_len <= 4:\n",
    "        # not enough tail samples for gpdfit\n",
    "        k = np.inf\n",
    "    else:\n",
    "        # order of tail samples\n",
    "        x_tail_si = np.argsort(x_tail)\n",
    "        # fit generalized Pareto distribution to the right tail samples\n",
    "        x_tail = np.exp(x_tail) - expxcutoff\n",
    "        k, sigma = _gpdfit(x_tail[x_tail_si])\n",
    "\n",
    "        if k >= k_min:\n",
    "            # no smoothing if short tail or GPD fit failed\n",
    "            # compute ordered statistic for the fit\n",
    "            sti = np.arange(0.5, tail_len) / tail_len\n",
    "            smoothed_tail = _gpinv(sti, k, sigma)\n",
    "            smoothed_tail = np.log(  # pylint: disable=assignment-from-no-return\n",
    "                smoothed_tail + expxcutoff\n",
    "            )\n",
    "            # place the smoothed tail into the output array\n",
    "            x[tailinds[x_tail_si]] = smoothed_tail\n",
    "            # truncate smoothed values to the largest raw weight 0\n",
    "            x[x > 0] = 0\n",
    "    # renormalize weights\n",
    "    x -= _logsumexp(x)\n",
    "\n",
    "    return x, k\n",
    "\n",
    "# not modified\n",
    "def _gpdfit(ary):\n",
    "    \"\"\"Estimate the parameters for the Generalized Pareto Distribution (GPD).\n",
    "    Empirical Bayes estimate for the parameters of the generalized Pareto\n",
    "    distribution given the data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    ary : array\n",
    "        sorted 1D data array\n",
    "    Returns\n",
    "    -------\n",
    "    k : float\n",
    "        estimated shape parameter\n",
    "    sigma : float\n",
    "        estimated scale parameter\n",
    "    \"\"\"\n",
    "    prior_bs = 3\n",
    "    prior_k = 10\n",
    "    n = len(ary)\n",
    "    m_est = 30 + int(n ** 0.5)\n",
    "\n",
    "    b_ary = 1 - np.sqrt(m_est / (np.arange(1, m_est + 1, dtype=float) - 0.5))\n",
    "    b_ary /= prior_bs * ary[int(n / 4 + 0.5) - 1]\n",
    "    b_ary += 1 / ary[-1]\n",
    "\n",
    "    k_ary = np.log1p(-b_ary[:, None] * ary).mean(axis=1)  # pylint: disable=no-member\n",
    "    len_scale = n * (np.log(-(b_ary / k_ary)) - k_ary - 1)\n",
    "    weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
    "\n",
    "    # remove negligible weights\n",
    "    real_idxs = weights >= 10 * np.finfo(float).eps\n",
    "    if not np.all(real_idxs):\n",
    "        weights = weights[real_idxs]\n",
    "        b_ary = b_ary[real_idxs]\n",
    "    # normalise weights\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    # posterior mean for b\n",
    "    b_post = np.sum(b_ary * weights)\n",
    "    # estimate for k\n",
    "    k_post = np.log1p(-b_post * ary).mean()  # pylint: disable=invalid-unary-operand-type,no-member\n",
    "    # add prior for k_post\n",
    "    k_post = (n * k_post + prior_k * 0.5) / (n + prior_k)\n",
    "    sigma = -k_post / b_post\n",
    "\n",
    "    return k_post, sigma\n",
    "\n",
    "# not modified\n",
    "def _gpinv(probs, kappa, sigma):\n",
    "    \"\"\"Inverse Generalized Pareto distribution function.\"\"\"\n",
    "    # pylint: disable=unsupported-assignment-operation, invalid-unary-operand-type\n",
    "    x = np.full_like(probs, np.nan)\n",
    "    if sigma <= 0:\n",
    "        return x\n",
    "    ok = (probs > 0) & (probs < 1)\n",
    "    if np.all(ok):\n",
    "        if np.abs(kappa) < np.finfo(float).eps:\n",
    "            x = -np.log1p(-probs)\n",
    "        else:\n",
    "            x = np.expm1(-kappa * np.log1p(-probs)) / kappa\n",
    "        x *= sigma\n",
    "    else:\n",
    "        if np.abs(kappa) < np.finfo(float).eps:\n",
    "            x[ok] = -np.log1p(-probs[ok])\n",
    "        else:\n",
    "            x[ok] = np.expm1(-kappa * np.log1p(-probs[ok])) / kappa\n",
    "        x *= sigma\n",
    "        x[probs == 0] = 0\n",
    "        if kappa >= 0:\n",
    "            x[probs == 1] = np.inf\n",
    "        else:\n",
    "            x[probs == 1] = -sigma / kappa\n",
    "    return x\n",
    "\n",
    "# not modified\n",
    "def _logsumexp(ary, *, b=None, b_inv=None, axis=None, keepdims=False, out=None, copy=True):\n",
    "    \"\"\"Stable logsumexp when b >= 0 and b is scalar.\n",
    "    b_inv overwrites b unless b_inv is None.\n",
    "    \"\"\"\n",
    "    # check dimensions for result arrays\n",
    "    ary = np.asarray(ary)\n",
    "    if ary.dtype.kind == \"i\":\n",
    "        ary = ary.astype(np.float64)\n",
    "    dtype = ary.dtype.type\n",
    "    shape = ary.shape\n",
    "    shape_len = len(shape)\n",
    "    if isinstance(axis, Sequence):\n",
    "        axis = tuple(axis_i if axis_i >= 0 else shape_len + axis_i for axis_i in axis)\n",
    "        agroup = axis\n",
    "    else:\n",
    "        axis = axis if (axis is None) or (axis >= 0) else shape_len + axis\n",
    "        agroup = (axis,)\n",
    "    shape_max = (\n",
    "        tuple(1 for _ in shape)\n",
    "        if axis is None\n",
    "        else tuple(1 if i in agroup else d for i, d in enumerate(shape))\n",
    "    )\n",
    "    # create result arrays\n",
    "    if out is None:\n",
    "        if not keepdims:\n",
    "            out_shape = (\n",
    "                tuple()\n",
    "                if axis is None\n",
    "                else tuple(d for i, d in enumerate(shape) if i not in agroup)\n",
    "            )\n",
    "        else:\n",
    "            out_shape = shape_max\n",
    "        out = np.empty(out_shape, dtype=dtype)\n",
    "    if b_inv == 0:\n",
    "        return np.full_like(out, np.inf, dtype=dtype) if out.shape else np.inf\n",
    "    if b_inv is None and b == 0:\n",
    "        return np.full_like(out, -np.inf) if out.shape else -np.inf\n",
    "    ary_max = np.empty(shape_max, dtype=dtype)\n",
    "    # calculations\n",
    "    ary.max(axis=axis, keepdims=True, out=ary_max)\n",
    "    if copy:\n",
    "        ary = ary.copy()\n",
    "    ary -= ary_max\n",
    "    np.exp(ary, out=ary)\n",
    "    ary.sum(axis=axis, keepdims=keepdims, out=out)\n",
    "    np.log(out, out=out)\n",
    "    if b_inv is not None:\n",
    "        ary_max -= np.log(b_inv)\n",
    "    elif b:\n",
    "        ary_max += np.log(b)\n",
    "    out += ary_max.squeeze() if not keepdims else ary_max\n",
    "    # transform to scalar if possible\n",
    "    return out if out.shape else dtype(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified\n",
    "def make_ufunc(func, n_dims=2, n_output=1, index=Ellipsis, ravel=True):  # noqa: D202\n",
    "    \"\"\"Make ufunc from a function taking 1D array input.\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "    n_dims : int, optional\n",
    "        Number of core dimensions not broadcasted. Dimensions are skipped from the end.\n",
    "        At minimum n_dims > 0.\n",
    "    n_output : int, optional\n",
    "        Select number of results returned by `func`.\n",
    "        If n_output > 1, ufunc returns a tuple of objects else returns an object.\n",
    "    index : int, optional\n",
    "        Slice ndarray with `index`. Defaults to `Ellipsis`.\n",
    "    ravel : bool, optional\n",
    "        If true, ravel the ndarray before calling `func`.\n",
    "    Returns\n",
    "    -------\n",
    "    callable\n",
    "        ufunc wrapper for `func`.\n",
    "    \"\"\"\n",
    "    if n_dims < 1:\n",
    "        raise TypeError(\"n_dims must be one or higher.\")\n",
    "\n",
    "    def _ufunc(ary, *args, out=None, **kwargs):\n",
    "        \"\"\"General ufunc for single-output function.\"\"\"\n",
    "        if out is None:\n",
    "            out = np.empty(ary.shape[:-n_dims])\n",
    "        else:\n",
    "            if out.shape != ary.shape[:-n_dims]:\n",
    "                msg = \"Shape incorrect for `out`: {}.\".format(out.shape)\n",
    "                msg += \" Correct shape is {}\".format(ary.shape[:-n_dims])\n",
    "                raise TypeError(msg)\n",
    "        for idx in np.ndindex(out.shape):\n",
    "            ary_idx = ary[idx].ravel() if ravel else ary[idx]\n",
    "            out[idx] = np.asarray(func(ary_idx, *args, **kwargs))[index]\n",
    "        return out\n",
    "\n",
    "    def _multi_ufunc(ary, *args, out=None, check_shape=True, **kwargs):\n",
    "        \"\"\"General ufunc for multi-output function.\"\"\"\n",
    "        element_shape = ary.shape[:-n_dims]\n",
    "        if out is None:\n",
    "            out = tuple(np.empty(element_shape) for _ in range(n_output))\n",
    "        elif check_shape:\n",
    "            raise_error = False\n",
    "            correct_shape = tuple(element_shape for _ in range(n_output))\n",
    "            if isinstance(out, tuple):\n",
    "                out_shape = tuple(item.shape for item in out)\n",
    "                if out_shape != correct_shape:\n",
    "                    raise_error = True\n",
    "            else:\n",
    "                raise_error = True\n",
    "                out_shape = \"not tuple, type={}\".format(type(out))\n",
    "            if raise_error:\n",
    "                msg = \"Shapes incorrect for `out`: {}.\".format(out_shape)\n",
    "                msg += \" Correct shapes are {}\".format(correct_shape)\n",
    "                raise TypeError(msg)\n",
    "        for idx in np.ndindex(element_shape):\n",
    "            ary_idx = ary[idx].ravel() if ravel else ary[idx]\n",
    "            results = func(ary_idx, *args, **kwargs)\n",
    "            for i, res in enumerate(results):\n",
    "                out[i][idx] = np.asarray(res)[index]\n",
    "        return out\n",
    "\n",
    "    if n_output > 1:\n",
    "        ufunc = _multi_ufunc\n",
    "    else:\n",
    "        ufunc = _ufunc\n",
    "\n",
    "    return ufunc\n",
    "\n",
    "# not modified\n",
    "def wrap_xarray_ufunc(\n",
    "    ufunc, dataset, *, ufunc_kwargs=None, func_args=None, func_kwargs=None, **kwargs\n",
    "):\n",
    "    \"\"\"Wrap make_ufunc with xarray.apply_ufunc.\n",
    "    Parameters\n",
    "    ----------\n",
    "    ufunc : callable\n",
    "    dataset : xarray.dataset\n",
    "    ufunc_kwargs : dict\n",
    "        Keyword arguments passed to `make_ufunc`.\n",
    "            - 'n_dims', int, by default 2\n",
    "            - 'n_output', int, by default 1\n",
    "            - 'index', slice, by default Ellipsis\n",
    "            - 'ravel', bool, by default True\n",
    "    func_args : tuple\n",
    "        Arguments passed to 'ufunc'.\n",
    "    func_kwargs : dict\n",
    "        Keyword arguments passed to 'ufunc'.\n",
    "    **kwargs\n",
    "        Passed to xarray.apply_ufunc.\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.dataset\n",
    "    \"\"\"\n",
    "    if ufunc_kwargs is None:\n",
    "        ufunc_kwargs = {}\n",
    "    if func_args is None:\n",
    "        func_args = tuple()\n",
    "    if func_kwargs is None:\n",
    "        func_kwargs = {}\n",
    "\n",
    "    callable_ufunc = make_ufunc(ufunc, **ufunc_kwargs)\n",
    "\n",
    "    kwargs.setdefault(\n",
    "        \"input_core_dims\", tuple((\"chain\", \"draw\") for _ in range(len(func_args) + 1))\n",
    "    )\n",
    "    kwargs.setdefault(\"output_core_dims\", tuple([] for _ in range(ufunc_kwargs.get(\"n_output\", 1))))\n",
    "\n",
    "    return apply_ufunc(callable_ufunc, dataset, *func_args, kwargs=func_kwargs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = az.load_arviz_data(\"radon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_psislw(idata, reff):\n",
    "    # get log_likelihood as dataarray\n",
    "    log_likelihood = idata.sample_stats.log_likelihood\n",
    "    dims = log_likelihood.dims\n",
    "    if len(dims)>3:\n",
    "        log_likelihood = log_likelihood.stack(\n",
    "            data_points=dims[2:], samples=('chain','draw')\n",
    "        )\n",
    "    else:\n",
    "        log_likelihood = log_likelihood.stack(samples=('chain','draw'))\n",
    "            \n",
    "    n_data_points, n_samples = log_likelihood.shape\n",
    "    \n",
    "    # precalculate constants\n",
    "    cutoff_ind = -int(np.ceil(min(n_samples / 5.0, 3 * (n_samples / reff) ** 0.5))) - 1\n",
    "    cutoffmin = np.log(np.finfo(float).tiny)  # pylint: disable=no-member, assignment-from-no-return\n",
    "    k_min = 1.0 / 3\n",
    "    \n",
    "    # create output array with proper dimensions\n",
    "    out = tuple([np.empty((n_data_points, n_samples, )), np.empty(n_data_points)])\n",
    "    \n",
    "    # define kwargs\n",
    "    func_kwargs = {\n",
    "        \"cutoff_ind\": cutoff_ind, \"cutoffmin\": cutoffmin, \"k_min\": k_min, \"reff\": reff, \"out\": out, \"check_shape\": False\n",
    "    }\n",
    "    ufunc_kwargs = {\"n_dims\": 1, \"n_output\": 2, \"ravel\": False}\n",
    "    kwargs = {\"input_core_dims\": [[\"samples\"]], \"output_core_dims\": [[\"sample\"], []]}\n",
    "    return wrap_xarray_ufunc(\n",
    "        psislw_1D, -log_likelihood, ufunc_kwargs=ufunc_kwargs, func_kwargs=func_kwargs, **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_weights_ufunc, pareto_shape_ufunc = new_psislw(idata, reff=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_array = idata.sample_stats.log_likelihood.values.reshape((2000, -1))\n",
    "log_weights, pareto_shape = psislw(-likelihood_array, reff=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'log_likelihood' (observed_county: 919, sample: 2000)>\n",
       "array([[-7.676019, -7.687702, -7.612622, ..., -7.790524, -7.751493, -7.414585],\n",
       "       [-7.591369, -7.562823, -7.5597  , ..., -7.492618, -7.541019, -7.607902],\n",
       "       [-7.628698, -7.608283, -7.575296, ..., -7.592743, -7.614087, -7.50912 ],\n",
       "       ...,\n",
       "       [-7.623555, -7.416671, -7.503158, ..., -7.556556, -7.633291, -7.510359],\n",
       "       [-7.600772, -7.597215, -7.583739, ..., -7.67111 , -7.693243, -7.656093],\n",
       "       [-7.586978, -7.599644, -7.607762, ..., -7.739501, -7.777954, -7.755855]])\n",
       "Coordinates:\n",
       "  * observed_county  (observed_county) object 'AITKIN' ... 'YELLOW MEDICINE'\n",
       "Dimensions without coordinates: sample"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.all(np.isclose(log_weights.T, log_weights_ufunc.values)))\n",
    "log_weights_ufunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'log_likelihood' (observed_county: 919)>\n",
       "array([0.138319, 0.191819, 0.247365, ..., 0.198977, 0.004341, 0.041028])\n",
       "Coordinates:\n",
       "  * observed_county  (observed_county) object 'AITKIN' ... 'YELLOW MEDICINE'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.all(np.isclose(pareto_shape, pareto_shape_ufunc.values)))\n",
    "pareto_shape_ufunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit log_weights_ufunc, pareto_shape_ufunc = new_psislw(idata, reff=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 ms ± 4.95 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "likelihood_array = idata.sample_stats.log_likelihood.values.reshape((2000, -1))\n",
    "log_weights, pareto_shape = psislw(-likelihood_array, reff=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
